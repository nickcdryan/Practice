{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "from textblob import TextBlob as blob\n",
    "from scipy import stats\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import sentiment as vaderSentiment \n",
    "\n",
    "# sentiment analysis\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from pattern.en import sentiment, mood, modality, wordnet, ADJECTIVE\n",
    "\n",
    "# text parsing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from spacy.en import English, STOPWORDS\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "# modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import lda\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "\n",
    "# visualization\n",
    "import pyLDAvis\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.test\n",
    "\n",
    "# pull tweets out of mongo\n",
    "def out_of_mongo(collection):\n",
    "    tweet_list = []\n",
    "    for tweet in collection.find():\n",
    "        tweet_list.append(tweet)\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trump data\n",
    "dt_data = out_of_mongo(db.trumptweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# convert to pandas df\n",
    "def data_to_df(data):\n",
    "    # variables explained: https://dev.twitter.com/overview/api/tweets\n",
    "    df = pd.DataFrame(data)\n",
    "    df.drop_duplicates(subset = 'id', inplace = True)\n",
    "    keep = ['id', 'created_at', 'text', \n",
    "            'favorite_count', 'retweet_count',  \n",
    "            'is_quote_status', 'quoted_status', 'quoted_status_id', \n",
    "            'in_reply_to_screen_name', 'in_reply_to_status_id', 'retweeted_status', \n",
    "            'entities', 'source']\n",
    "    df = df[keep]\n",
    "    return df\n",
    "\n",
    "dt = data_to_df(dt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quoted_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000e+02</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.274467e+17</td>\n",
       "      <td>17548.981667</td>\n",
       "      <td>6353.610000</td>\n",
       "      <td>7.146530e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.636266e+16</td>\n",
       "      <td>14577.500224</td>\n",
       "      <td>5191.303563</td>\n",
       "      <td>3.672723e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.751208e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>6.743172e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.771484e+17</td>\n",
       "      <td>4702.500000</td>\n",
       "      <td>2115.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.462896e+17</td>\n",
       "      <td>14627.000000</td>\n",
       "      <td>5197.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.583705e+17</td>\n",
       "      <td>26317.750000</td>\n",
       "      <td>8902.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.622845e+17</td>\n",
       "      <td>83230.000000</td>\n",
       "      <td>31203.000000</td>\n",
       "      <td>7.612773e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  favorite_count  retweet_count  quoted_status_id\n",
       "count  6.000000e+02      600.000000     600.000000      1.300000e+01\n",
       "mean   7.274467e+17    17548.981667    6353.610000      7.146530e+17\n",
       "std    3.636266e+16    14577.500224    5191.303563      3.672723e+16\n",
       "min    6.751208e+17        0.000000     434.000000      6.743172e+17\n",
       "25%    6.771484e+17     4702.500000    2115.250000               NaN\n",
       "50%    7.462896e+17    14627.000000    5197.000000               NaN\n",
       "75%    7.583705e+17    26317.750000    8902.750000               NaN\n",
       "max    7.622845e+17    83230.000000   31203.000000      7.612773e+17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_retweet(retweeted_status):\n",
    "    \"\"\"Check if tweet is retweet.\"\"\"\n",
    "    try:\n",
    "        if np.isnan(retweeted_status) == True:\n",
    "            return \n",
    "    except:\n",
    "        return 1\n",
    "    \n",
    "def get_week(date):\n",
    "    \"\"\"Return start of week (Monday) given a date.\"\"\"\n",
    "    week = date - timedelta(days = date.weekday())\n",
    "    return week\n",
    "\n",
    "def add_metadata(df):\n",
    "    \"\"\"Add date, is retweet, month, and week features to df.\"\"\"\n",
    "    # add date as datetime object\n",
    "    df.loc[:, 'date'] = df.loc[:, 'created_at'].apply(lambda x: pd.to_datetime(x).date())\n",
    "    \n",
    "    # add if retweet\n",
    "    df.loc[:, 'is_retweet'] = df.loc[:, 'retweeted_status'].apply(is_retweet)\n",
    "    \n",
    "    # add week\n",
    "    df.loc[:, 'week'] = df.loc[:, 'date'].apply(get_week)\n",
    "    \n",
    "    # add month\n",
    "    df.loc[:, 'month'] = df.loc[:, 'date'].apply(lambda x: x.replace(day = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_metadata(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_feats(df, featurelist): \n",
    "    \"\"\"Plot features of dataframe\n",
    "    Args:\n",
    "    df (dataframe) -- dataframe\n",
    "    featurelist (list) -- list of features to plot\n",
    "    \"\"\"    \n",
    "    plt.figure(figsize = (20, 8))\n",
    "    plt.title('Retweets and Favorites', fontsize = 14)\n",
    "    for feature in featurelist:\n",
    "        plt.plot(df[feature])\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare retweets vs. favorites\n",
    "\n",
    "plot_feats(dt, ['retweet_count', 'favorite_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group by date\n",
    "\n",
    "groupby_date_fav = dt['favorite_count'].groupby(dt['date'])\n",
    "groupby_date_rt = dt['retweet_count'].groupby(dt['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015-12-11    2086.714286\n",
       "2015-12-12    2097.086957\n",
       "2015-12-13    1273.342857\n",
       "2015-12-14    2229.315789\n",
       "2015-12-15    1302.037037\n",
       "Name: retweet_count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanfav_df = groupby_date_fav.mean()\n",
    "meanrt_df = groupby_date_rt.mean()\n",
    "meanfav_df.head()\n",
    "meanrt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# favorites and retweets reduced variance (by date)\n",
    "\n",
    "def plot_compare(dfs): \n",
    "    plt.figure(figsize = (20, 8))\n",
    "    plt.title('Mean Retweets and Favorites', fontsize = 14)\n",
    "    for df in dfs:\n",
    "        plt.plot(df)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    \n",
    "plot_compare([meanfav_df, meanrt_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize tweets, with a number of options:\n",
    "#\n",
    "# word_tokenizer from nltk\n",
    "# TweetTokenizer from nltk\n",
    "# Custom tokenizer from https://marcobonzanini.com/2015/03/09/mining-twitter-data-with-python-part-2/\n",
    "\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt.loc[:, 'sentences'] = dt.loc[:, 'text'].apply(sent_tokenize)\n",
    "dt.loc[:, 'tokens']    = dt.loc[:, 'text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>entities</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762284533341417472</td>\n",
       "      <td>Sun Aug 07 13:49:29 +0000 2016</td>\n",
       "      <td>I see where Mayor Stephanie Rawlings-Blake of ...</td>\n",
       "      <td>18689</td>\n",
       "      <td>6343</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>[I see where Mayor Stephanie Rawlings-Blake of...</td>\n",
       "      <td>[I, see, where, Mayor, Stephanie, Rawlings-Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>762110918721310721</td>\n",
       "      <td>Sun Aug 07 02:19:37 +0000 2016</td>\n",
       "      <td>Thank you Windham, New Hampshire! #TrumpPence1...</td>\n",
       "      <td>15984</td>\n",
       "      <td>4818</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>[Thank you Windham, New Hampshire!, #TrumpPenc...</td>\n",
       "      <td>[Thank, you, Windham, ,, New, Hampshire, !, #T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>762106904436961280</td>\n",
       "      <td>Sun Aug 07 02:03:39 +0000 2016</td>\n",
       "      <td>.@Larry_Kudlow - 'Donald Trump Is the middle-c...</td>\n",
       "      <td>16312</td>\n",
       "      <td>6547</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'indices...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>[., @Larry_Kudlow - 'Donald Trump Is the middl...</td>\n",
       "      <td>[., @Larry_Kudlow, -, ', Donald, Trump, Is, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>762104411707568128</td>\n",
       "      <td>Sun Aug 07 01:53:45 +0000 2016</td>\n",
       "      <td>I am not just running against Crooked Hillary ...</td>\n",
       "      <td>60500</td>\n",
       "      <td>19862</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>[I am not just running against Crooked Hillary...</td>\n",
       "      <td>[I, am, not, just, running, against, Crooked, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>762016426102296576</td>\n",
       "      <td>Sat Aug 06 20:04:08 +0000 2016</td>\n",
       "      <td>#CrookedHillary is not fit to be our next pres...</td>\n",
       "      <td>21357</td>\n",
       "      <td>7160</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>[#CrookedHillary is not fit to be our next pre...</td>\n",
       "      <td>[#CrookedHillary, is, not, fit, to, be, our, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                      created_at  \\\n",
       "0  762284533341417472  Sun Aug 07 13:49:29 +0000 2016   \n",
       "1  762110918721310721  Sun Aug 07 02:19:37 +0000 2016   \n",
       "2  762106904436961280  Sun Aug 07 02:03:39 +0000 2016   \n",
       "3  762104411707568128  Sun Aug 07 01:53:45 +0000 2016   \n",
       "4  762016426102296576  Sat Aug 06 20:04:08 +0000 2016   \n",
       "\n",
       "                                                text  favorite_count  \\\n",
       "0  I see where Mayor Stephanie Rawlings-Blake of ...           18689   \n",
       "1  Thank you Windham, New Hampshire! #TrumpPence1...           15984   \n",
       "2  .@Larry_Kudlow - 'Donald Trump Is the middle-c...           16312   \n",
       "3  I am not just running against Crooked Hillary ...           60500   \n",
       "4  #CrookedHillary is not fit to be our next pres...           21357   \n",
       "\n",
       "   retweet_count is_quote_status quoted_status  quoted_status_id  \\\n",
       "0           6343           False           NaN               NaN   \n",
       "1           4818           False           NaN               NaN   \n",
       "2           6547           False           NaN               NaN   \n",
       "3          19862           False           NaN               NaN   \n",
       "4           7160           False           NaN               NaN   \n",
       "\n",
       "  in_reply_to_screen_name in_reply_to_status_id retweeted_status  \\\n",
       "0                    None                  None              NaN   \n",
       "1                    None                  None              NaN   \n",
       "2                    None                  None              NaN   \n",
       "3                    None                  None              NaN   \n",
       "4                    None                  None              NaN   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {u'symbols': [], u'user_mentions': [], u'hasht...   \n",
       "1  {u'symbols': [], u'user_mentions': [], u'hasht...   \n",
       "2  {u'symbols': [], u'user_mentions': [{u'indices...   \n",
       "3  {u'symbols': [], u'user_mentions': [], u'hasht...   \n",
       "4  {u'symbols': [], u'user_mentions': [], u'hasht...   \n",
       "\n",
       "                                              source        date  is_retweet  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...  2016-08-07         NaN   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...  2016-08-07         NaN   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...  2016-08-07         NaN   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...  2016-08-07         NaN   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...  2016-08-06         NaN   \n",
       "\n",
       "         week       month                                          sentences  \\\n",
       "0  2016-08-01  2016-08-01  [I see where Mayor Stephanie Rawlings-Blake of...   \n",
       "1  2016-08-01  2016-08-01  [Thank you Windham, New Hampshire!, #TrumpPenc...   \n",
       "2  2016-08-01  2016-08-01  [., @Larry_Kudlow - 'Donald Trump Is the middl...   \n",
       "3  2016-08-01  2016-08-01  [I am not just running against Crooked Hillary...   \n",
       "4  2016-08-01  2016-08-01  [#CrookedHillary is not fit to be our next pre...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [I, see, where, Mayor, Stephanie, Rawlings-Bla...  \n",
       "1  [Thank, you, Windham, ,, New, Hampshire, !, #T...  \n",
       "2  [., @Larry_Kudlow, -, ', Donald, Trump, Is, th...  \n",
       "3  [I, am, not, just, running, against, Crooked, ...  \n",
       "4  [#CrookedHillary, is, not, fit, to, be, our, n...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English Word</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anticipation</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abatement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abba</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abdominal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abduction</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aberration</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abeyance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abhor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abhorrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abide</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    English Word  Positive  Negative  Anger  Anticipation  Disgust  Fear  Joy  \\\n",
       "1         abacus         0         0      0             0        0     0    0   \n",
       "2        abandon         0         1      0             0        0     1    0   \n",
       "3      abandoned         0         1      1             0        0     1    0   \n",
       "4    abandonment         0         1      1             0        0     1    0   \n",
       "5          abate         0         0      0             0        0     0    0   \n",
       "6      abatement         0         0      0             0        0     0    0   \n",
       "7           abba         1         0      0             0        0     0    0   \n",
       "8          abbot         0         0      0             0        0     0    0   \n",
       "9     abbreviate         0         0      0             0        0     0    0   \n",
       "10  abbreviation         0         0      0             0        0     0    0   \n",
       "11       abdomen         0         0      0             0        0     0    0   \n",
       "12     abdominal         0         0      0             0        0     0    0   \n",
       "13     abduction         0         1      0             0        0     1    0   \n",
       "14      aberrant         0         1      0             0        0     0    0   \n",
       "15    aberration         0         1      0             0        1     0    0   \n",
       "16      abeyance         0         0      0             0        0     0    0   \n",
       "17         abhor         0         1      1             0        1     1    0   \n",
       "18     abhorrent         0         1      1             0        1     1    0   \n",
       "19         abide         0         0      0             0        0     0    0   \n",
       "\n",
       "    Sadness  Surprise  Trust  \n",
       "1         0         0      1  \n",
       "2         1         0      0  \n",
       "3         1         0      0  \n",
       "4         1         1      0  \n",
       "5         0         0      0  \n",
       "6         0         0      0  \n",
       "7         0         0      0  \n",
       "8         0         0      1  \n",
       "9         0         0      0  \n",
       "10        0         0      0  \n",
       "11        0         0      0  \n",
       "12        0         0      0  \n",
       "13        1         1      0  \n",
       "14        0         0      0  \n",
       "15        0         0      0  \n",
       "16        0         0      0  \n",
       "17        0         0      0  \n",
       "18        0         0      0  \n",
       "19        0         0      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_lexicon = pd.read_csv('NRC_Emotion_Lexicon.csv', header=0)\n",
    "emotion_lexicon[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mini = pd.DataFrame([[['abide', 'abhorrent', 'abhor', 'abeyance']],\n",
    "              [['aberration','aberrant','abduction']],\n",
    "              [['abdominal','abdomen','abbreviation']],\n",
    "              [['sfsadf','asdfasf','asdfjsf']],\n",
    "              [['abbreviate','abbot','abba']]])\n",
    "\n",
    "mini.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abide, abhorrent, abhor, abeyance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[aberration, aberrant, abduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[abdominal, abdomen, abbreviation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sfsadf, asdfasf, asdfjsf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[abbreviate, abbot, abba]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 words\n",
       "0  [abide, abhorrent, abhor, abeyance]\n",
       "1    [aberration, aberrant, abduction]\n",
       "2   [abdominal, abdomen, abbreviation]\n",
       "3           [sfsadf, asdfasf, asdfjsf]\n",
       "4            [abbreviate, abbot, abba]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>affect</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent,0,1,0,0,0,0,0,1,0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absentee,0,1,0,0,0,0,0,1,0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absenteeism,0,1,0,0,0,0,0,0,0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absinthe,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolute,1,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  affect  flag\n",
       "0       absent,0,1,0,0,0,0,0,1,0,0     NaN   NaN\n",
       "1     absentee,0,1,0,0,0,0,0,1,0,0     NaN   NaN\n",
       "2  absenteeism,0,1,0,0,0,0,0,0,0,0     NaN   NaN\n",
       "3     absinthe,0,0,0,0,0,0,0,0,0,0     NaN   NaN\n",
       "4     absolute,1,0,0,0,0,0,0,0,0,0     NaN   NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datat = pd.read_csv('NRC_Emotion_Lexicon.csv', delim_whitespace=True, skiprows=45, header=None, names=['word', 'affect', 'flag'])\n",
    "datat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_sentiment(self):\n",
    "    # Load up the NRC emotion lexicon\n",
    "\n",
    "    data = pd.read_csv('NRC_Emotion_Lexicon.csv', delim_whitespace=True, skiprows=45, header=None, names=['word', 'affect', 'flag'])\n",
    "\n",
    "    emotion_words = dict()\n",
    "    emotion_map = dict()\n",
    "    affects = ['positive', 'negative', 'anger', 'anticipation', 'disgust',\n",
    "               'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "    for key in affects:\n",
    "        emotion_words[key] = data[(data['affect'] == key) & (data['flag'] == 1)]['word'].tolist()\n",
    "        emotion_map[key] = list()\n",
    "\n",
    "    for text in self.data:  # Note no stemming or it may fail to match words\n",
    "        words = Counter([i.lower() for i in wordpunct_tokenize(text)\n",
    "                     if i.lower() not in self.stop_words and not i.lower().startswith('http')])\n",
    "        for key in emotion_words.keys():\n",
    "            x = set(emotion_words[key]).intersection(words.keys())\n",
    "            emotion_map[key].append(len(x))\n",
    "    self.sentiment = pd.DataFrame(emotion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-515aa12c73c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-b7e9cb42ddc9>\u001b[0m in \u001b[0;36mget_sentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m                'fear', 'joy', 'sadness', 'surprise', 'trust']\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0memotion_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'affect'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0memotion_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickryan/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/Users/nickryan/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "get_sentiment(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_disgust(text):\n",
    "    disgust = 0\n",
    "    for i in text:\n",
    "        for word in emotion_lexicon['English Word']:\n",
    "            if i == word && \n",
    "    \n",
    "    \n",
    "\n",
    "def add_emotions(df):\n",
    "    # add disgust\n",
    "    %time df.loc[:, 'disgust'] = df.loc[:, 'words'].apply(get_sentences)\n",
    "    \n",
    "    # add fear\n",
    "    %time df.loc[:, 'fear'] = df.loc[:, 'words'].apply(get_tokens)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop words, stemming, etc. cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    \"\"\"Return list of sentences in tweet.\"\"\"\n",
    "    sents = sent_tokenize(text)\n",
    "    return [sent for sent in sents if re.search('[a-zA-Z]', sent) != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polarity(sents):\n",
    "    \"\"\"Return polarity score for each sentence in text.\"\"\"\n",
    "    return [sentiment(x)[0] for x in sents]\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    \"\"\"Return vaderSentiment score for text.\"\"\"\n",
    "    try:\n",
    "        return vaderSentiment(text)['compound']\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_subjectivity(sents):\n",
    "    \"\"\"Return subjectivity score for each sentence in text.\"\"\"\n",
    "    return [sentiment(x)[1] for x in sents]\n",
    "\n",
    "def get_is_fact(sents):\n",
    "    \"\"\"Return modality score for each sentence in text.\"\"\"\n",
    "    return [modality(x) for x in sents]\n",
    "\n",
    "def get_mood(sents):\n",
    "    \"\"\"Return modality score for each sentence in text.\"\"\"\n",
    "    return [mood(x) for x in sents]\n",
    "\n",
    "def get_mood_mode(mood):\n",
    "    \"\"\"Return most commonly occuring modality score for each tweet.\"\"\"\n",
    "    try:\n",
    "        return stats.mode(mood)[0][0]\n",
    "    except:\n",
    "        return mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get hashtags and mentions\n",
    "def get_hashtags(entities):\n",
    "    \"\"\"Return a list of all hashtags used in tweet.\"\"\"\n",
    "    try:\n",
    "        return [entities['hashtags'][i]['text'] for i in range(len(entities['hashtags']))]\n",
    "    except:\n",
    "        return \n",
    "\n",
    "def get_user_mentions(entities):\n",
    "    \"\"\"Return a list of all user mentions in tweet.\"\"\"\n",
    "    try:\n",
    "        return [entities['user_mentions'][i]['screen_name'] for i in range(len(entities['user_mentions']))]\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "def get_first_hashtag(entities):\n",
    "    \"\"\"Return first hashtag used in tweet.\"\"\"\n",
    "    try:\n",
    "        return [entities['hashtags'][i]['text'] for i in range(len(entities['hashtags']))][0]\n",
    "    except:\n",
    "        return \n",
    "\n",
    "def get_first_user_mentions(entities):\n",
    "    \"\"\"Return first user mentioned in tweet.\"\"\"\n",
    "    try:\n",
    "        return [entities['user_mentions'][i]['screen_name'] for i in range(len(entities['user_mentions']))][0]\n",
    "    except:\n",
    "        return\n",
    "\n",
    "def has_media(entities):\n",
    "    \"\"\"Return type of media if tweet contains media, blank if not.\"\"\"\n",
    "    try:\n",
    "        return entities['media'][0]['type']\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(text):  \n",
    "    \"\"\"Return lemmatized tokens for each review.\"\"\"\n",
    "    text = re.sub(r\"http\\S+\", \"hyperlink\", text) # replace urls with str hyperlink\n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9@]\", \" \", text) # remove everything except numbers, hashtags, and @\n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    try:\n",
    "        tokens = [token.lemma_ for token in nlp(words)] # get lemmas\n",
    "    except:\n",
    "        tokens = [token.lemma_ for token in nlp(words.decode('utf8'))] # get lemmas\n",
    "    filtered = [t for t in tokens if t != '' and t != ' ' and t != '\\n' and t != '\\n\\n'] # remove any remaining spaces\n",
    "    filtered = [t for t in filtered if any(letter.isalpha() for letter in t)] # remove numbers without any letters attached\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    # add sentences\n",
    "    %time df.loc[:, 'sentences'] = df.loc[:, 'text'].apply(get_sentences)\n",
    "    \n",
    "    # add tokens\n",
    "    %time df.loc[:, 'tokens'] = df.loc[:, 'text'].apply(get_tokens)\n",
    "    \n",
    "    # add sentiment, subjectivity, modality, and mood scores by sentence\n",
    "    %time df.loc[:, 'sentiment'] = df.loc[:, 'sentences'].apply(get_polarity)\n",
    "    %time df.loc[:, 'mood'] = df.loc[:, 'sentences'].apply(get_mood)\n",
    "    %time df.loc[:, 'modality'] = df.loc[:, 'sentences'].apply(get_is_fact)\n",
    "    %time df.loc[:, 'subjectivity'] = df.loc[:, 'sentences'].apply(get_subjectivity)\n",
    "    %time df.loc[:, 'vader_sentiment'] = df.loc[:, 'text'].apply(get_vader_sentiment)\n",
    "\n",
    "    \n",
    "    # average the above scores\n",
    "    %time df.loc[:, 'avg_sentiment'] = df.loc[:, 'sentiment'].apply(np.mean)\n",
    "    %time df.loc[:, 'mode_mood'] = df.loc[:, 'mood'].apply(get_mood_mode)\n",
    "    %time df.loc[:, 'avg_modality'] = df.loc[:, 'modality'].apply(np.mean)\n",
    "    %time df.loc[:, 'avg_subjectivity'] = df.loc[:, 'subjectivity'].apply(np.mean)\n",
    "    \n",
    "    # count number of tokens\n",
    "    df.loc[:, 'num_tokens'] = df.loc[:, 'tokens'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # count number of characters\n",
    "    df.loc[:, 'num_chars'] = df.loc[:, 'tokens'].apply(lambda x: len(x))\n",
    "    \n",
    "    # add user mentions, hashtags, and media\n",
    "    df.loc[:, 'hashtags'] = df.loc[:, 'entities'].apply(get_hashtags)\n",
    "    df.loc[:, 'user_mentions'] = df.loc[:, 'entities'].apply(get_user_mentions)\n",
    "    df.loc[:, 'media'] = df.loc[:, 'entities'].apply(has_media)\n",
    "    \n",
    "    # count number of hyperlinks\n",
    "    df.loc[:, 'num_hyperlinks'] = df.loc[:, 'tokens'].apply(lambda x: x.split().count('hyperlink'))\n",
    "    \n",
    "    # return first hashtag\n",
    "    df.loc[:, 'first_hashtag'] = df.loc[:, 'entities'].apply(get_first_hashtag)\n",
    "    \n",
    "    # return first user mention\n",
    "    df.loc[:, 'first_user_mention'] = df.loc[:, 'entities'].apply(get_first_user_mentions)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load spacy, stopwords, and punctuation\n",
    "nlp = spacy.en.English()\n",
    "stop = STOPWORDS\n",
    "punct = {p for p in string.punctuation if p != '@' and p != '#'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_features(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_modality</th>\n",
       "      <th>avg_subjectivity</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>media</th>\n",
       "      <th>num_hyperlinks</th>\n",
       "      <th>first_hashtag</th>\n",
       "      <th>first_user_mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762284533341417472</td>\n",
       "      <td>Sun Aug 07 13:49:29 +0000 2016</td>\n",
       "      <td>I see where Mayor Stephanie Rawlings-Blake of ...</td>\n",
       "      <td>18689</td>\n",
       "      <td>6343</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.106944</td>\n",
       "      <td>26</td>\n",
       "      <td>131</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>762110918721310721</td>\n",
       "      <td>Sun Aug 07 02:19:37 +0000 2016</td>\n",
       "      <td>Thank you Windham, New Hampshire! #TrumpPence1...</td>\n",
       "      <td>15984</td>\n",
       "      <td>4818</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>[TrumpPence16, MAGA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>photo</td>\n",
       "      <td>1</td>\n",
       "      <td>TrumpPence16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>762106904436961280</td>\n",
       "      <td>Sun Aug 07 02:03:39 +0000 2016</td>\n",
       "      <td>.@Larry_Kudlow - 'Donald Trump Is the middle-c...</td>\n",
       "      <td>16312</td>\n",
       "      <td>6547</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>[]</td>\n",
       "      <td>[larry_kudlow]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>larry_kudlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>762104411707568128</td>\n",
       "      <td>Sun Aug 07 01:53:45 +0000 2016</td>\n",
       "      <td>I am not just running against Crooked Hillary ...</td>\n",
       "      <td>60500</td>\n",
       "      <td>19862</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>24</td>\n",
       "      <td>126</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>762016426102296576</td>\n",
       "      <td>Sat Aug 06 20:04:08 +0000 2016</td>\n",
       "      <td>#CrookedHillary is not fit to be our next pres...</td>\n",
       "      <td>21357</td>\n",
       "      <td>7160</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>[CrookedHillary, TrumpPence16]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>CrookedHillary</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                      created_at  \\\n",
       "0  762284533341417472  Sun Aug 07 13:49:29 +0000 2016   \n",
       "1  762110918721310721  Sun Aug 07 02:19:37 +0000 2016   \n",
       "2  762106904436961280  Sun Aug 07 02:03:39 +0000 2016   \n",
       "3  762104411707568128  Sun Aug 07 01:53:45 +0000 2016   \n",
       "4  762016426102296576  Sat Aug 06 20:04:08 +0000 2016   \n",
       "\n",
       "                                                text  favorite_count  \\\n",
       "0  I see where Mayor Stephanie Rawlings-Blake of ...           18689   \n",
       "1  Thank you Windham, New Hampshire! #TrumpPence1...           15984   \n",
       "2  .@Larry_Kudlow - 'Donald Trump Is the middle-c...           16312   \n",
       "3  I am not just running against Crooked Hillary ...           60500   \n",
       "4  #CrookedHillary is not fit to be our next pres...           21357   \n",
       "\n",
       "   retweet_count is_quote_status quoted_status  quoted_status_id  \\\n",
       "0           6343           False           NaN               NaN   \n",
       "1           4818           False           NaN               NaN   \n",
       "2           6547           False           NaN               NaN   \n",
       "3          19862           False           NaN               NaN   \n",
       "4           7160           False           NaN               NaN   \n",
       "\n",
       "  in_reply_to_screen_name in_reply_to_status_id        ...          \\\n",
       "0                    None                  None        ...           \n",
       "1                    None                  None        ...           \n",
       "2                    None                  None        ...           \n",
       "3                    None                  None        ...           \n",
       "4                    None                  None        ...           \n",
       "\n",
       "  avg_modality avg_subjectivity num_tokens num_chars  \\\n",
       "0     0.833333         0.106944         26       131   \n",
       "1     1.000000         0.227273          8        59   \n",
       "2     0.750000         0.000000         11        73   \n",
       "3     0.750000         0.475000         24       126   \n",
       "4     0.750000         0.100000         11        73   \n",
       "\n",
       "                         hashtags   user_mentions  media num_hyperlinks  \\\n",
       "0                              []              []   None              0   \n",
       "1            [TrumpPence16, MAGA]              []  photo              1   \n",
       "2                              []  [larry_kudlow]   None              1   \n",
       "3                              []              []   None              0   \n",
       "4  [CrookedHillary, TrumpPence16]              []   None              1   \n",
       "\n",
       "    first_hashtag first_user_mention  \n",
       "0            None               None  \n",
       "1    TrumpPence16               None  \n",
       "2            None       larry_kudlow  \n",
       "3            None               None  \n",
       "4  CrookedHillary               None  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
