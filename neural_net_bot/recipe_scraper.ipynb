{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2  \n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BeautifulSoup to scrape and parse a www.cookbooks.com page for recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recipe(index):\n",
    "    \n",
    "    # get webpage and use BeautifulSoup parser\n",
    "    quote_page = 'http://www.cookbooks.com/Recipe-Details.aspx?id=' + str(index)\n",
    "    page = urllib2.urlopen(quote_page)  \n",
    "    soup = BeautifulSoup(page, 'html.parser')    \n",
    "    \n",
    "    # recipe name\n",
    "    name_box = soup.find('p', attrs={'class': 'H2'})  \n",
    "    name = name_box.text.strip() \n",
    "\n",
    "    # ingredients html table and instructions html table\n",
    "    tables = soup.find_all('table', attrs={'width' : '100%', \n",
    "                                           'border' : '1px', \n",
    "                                           'cellspacing' : '0', \n",
    "                                           'cellpadding' : '10'})  \n",
    "    ingredients = tables[0]\n",
    "    instructions = tables[1]\n",
    "    \n",
    "    # print recipe\n",
    "    print name.encode('utf-8'), \"\\n\"\n",
    "\n",
    "    for string in ingredients.stripped_strings:\n",
    "        print(string.encode('utf-8'))\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    for string in instructions.stripped_strings:\n",
    "        print(string.encode('utf-8'))\n",
    "        \n",
    "    print \"\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and save recipes to a text file\n",
    "We'd like to collect about 3MB worth of data for training our nerual network, which is equivalent to about 6,000 recipes. In order to sample a diverse collection of recipes, we'll scrape every eigth recipe in cookbooks.com's over 49,000 recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# redirect stdout to text file\n",
    "orig_stdout = sys.stdout\n",
    "f = file('recipes2.txt', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "# iterate over pages, skip AttributeError for pages with recipe deleted from database\n",
    "for i in range(1,6000):\n",
    "    try:\n",
    "        get_recipe(i*8)\n",
    "        time.sleep(.5)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "        time.sleep(.5)\n",
    "\n",
    "# redirect stdout to original       \n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
